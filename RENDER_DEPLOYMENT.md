# ğŸš€ Despliegue del Modelo ML en Render

## ğŸ“‹ DescripciÃ³n

Este documento explica cÃ³mo desplegar el modelo de Machine Learning para predicciÃ³n de riego en Render.

## ğŸ› ï¸ Archivos Necesarios

### **1. `ml_api.py` - API Flask Principal**
- âœ… API REST para el modelo ML
- âœ… Endpoints para predicciÃ³n, entrenamiento y monitoreo
- âœ… Manejo de errores y validaciÃ³n de datos
- âœ… Soporte para predicciones en lote

### **2. `requirements_ml_render.txt` - Dependencias**
```
Flask==2.3.3
Flask-CORS==4.0.0
pandas==2.0.3
numpy==1.24.3
scikit-learn==1.3.0
joblib==1.3.2
gunicorn==21.2.0
```

### **3. `render.yaml` - ConfiguraciÃ³n de Render**
- âœ… ConfiguraciÃ³n automÃ¡tica del servicio
- âœ… Comandos de build y start
- âœ… Variables de entorno

## ğŸŒ Endpoints de la API

### **ğŸ  Home**
```
GET /
```
**Respuesta:**
```json
{
  "message": "ğŸŒ± IoT Irrigation Prediction API",
  "version": "1.0.0",
  "status": "active",
  "model_loaded": true,
  "endpoints": {...}
}
```

### **ğŸ” Health Check**
```
GET /health
```
**Respuesta:**
```json
{
  "status": "healthy",
  "timestamp": "2024-10-23T18:30:00",
  "model_loaded": true
}
```

### **ğŸ“Š Model Info**
```
GET /model-info
```
**Respuesta:**
```json
{
  "status": "success",
  "model_type": "RandomForestClassifier",
  "n_estimators": 100,
  "max_depth": 10,
  "feature_importance": {
    "temperature": 0.25,
    "humidity": 0.20,
    "soil_moisture": 0.35,
    "uv_index": 0.10,
    "hour": 0.05,
    "day_of_week": 0.05
  }
}
```

### **ğŸ”® PredicciÃ³n Individual**
```
POST /predict
```
**Datos de entrada:**
```json
{
  "temperature": 28.5,
  "humidity": 45.0,
  "soil_moisture": 25.0,
  "uv_index": 7.2
}
```
**Respuesta:**
```json
{
  "status": "success",
  "prediction": {
    "needs_irrigation": true,
    "confidence": 0.85,
    "probability_irrigation": 0.85
  },
  "input_data": {...},
  "timestamp": "2024-10-23T18:30:00"
}
```

### **ğŸ“¦ Predicciones en Lote**
```
POST /batch-predict
```
**Datos de entrada:**
```json
{
  "sensor_data": [
    {
      "temperature": 28.5,
      "humidity": 45.0,
      "soil_moisture": 25.0,
      "uv_index": 7.2
    },
    {
      "temperature": 30.0,
      "humidity": 40.0,
      "soil_moisture": 20.0,
      "uv_index": 8.5
    }
  ]
}
```

### **ğŸŒ± Entrenar Modelo**
```
POST /train
```
**Respuesta:**
```json
{
  "status": "success",
  "message": "Model trained successfully",
  "model_loaded": true,
  "timestamp": "2024-10-23T18:30:00"
}
```

## ğŸš€ Pasos para Desplegar en Render

### **1. Preparar el Repositorio**
```bash
# Agregar archivos al repositorio
git add ml_api.py requirements_ml_render.txt render.yaml
git commit -m "Add ML API for Render deployment"
git push origin main
```

### **2. Crear Cuenta en Render**
1. Ve a [render.com](https://render.com)
2. RegÃ­strate con GitHub
3. Conecta tu repositorio

### **3. Crear Nuevo Servicio Web**
1. **New** â†’ **Web Service**
2. **Connect Repository** â†’ Selecciona tu repo
3. **Configure:**
   - **Name:** `ml-irrigation-api`
   - **Environment:** `Python 3`
   - **Build Command:** `pip install -r requirements_ml_render.txt`
   - **Start Command:** `gunicorn ml_api:app`
   - **Plan:** Free

### **4. Variables de Entorno (Opcional)**
```
PYTHON_VERSION=3.11.0
```

### **5. Desplegar**
- Click **Create Web Service**
- Render construirÃ¡ y desplegarÃ¡ automÃ¡ticamente
- ObtendrÃ¡s una URL como: `https://ml-irrigation-api.onrender.com`

## ğŸ”§ ConfiguraciÃ³n Avanzada

### **Usar render.yaml (Recomendado)**
1. Agrega `render.yaml` al repositorio
2. Render detectarÃ¡ automÃ¡ticamente la configuraciÃ³n
3. Despliegue automÃ¡tico con la configuraciÃ³n especificada

### **ConfiguraciÃ³n Manual**
Si prefieres configurar manualmente:
- **Build Command:** `pip install -r requirements_ml_render.txt`
- **Start Command:** `gunicorn ml_api:app`
- **Python Version:** 3.11.0

## ğŸ“Š Uso de la API

### **Ejemplo con cURL:**
```bash
# Health check
curl https://tu-api.onrender.com/health

# PredicciÃ³n
curl -X POST https://tu-api.onrender.com/predict \
  -H "Content-Type: application/json" \
  -d '{
    "temperature": 28.5,
    "humidity": 45.0,
    "soil_moisture": 25.0,
    "uv_index": 7.2
  }'
```

### **Ejemplo con Python:**
```python
import requests

# URL de tu API en Render
api_url = "https://tu-api.onrender.com"

# Hacer predicciÃ³n
data = {
    "temperature": 28.5,
    "humidity": 45.0,
    "soil_moisture": 25.0,
    "uv_index": 7.2
}

response = requests.post(f"{api_url}/predict", json=data)
result = response.json()

print(f"Â¿Necesita riego? {result['prediction']['needs_irrigation']}")
print(f"Confianza: {result['prediction']['confidence']:.2f}")
```

## ğŸ”„ IntegraciÃ³n con el Sistema IoT

### **En el ESP32:**
```cpp
// Enviar datos al modelo ML
String jsonData = "{";
jsonData += "\"temperature\":" + String(temperature) + ",";
jsonData += "\"humidity\":" + String(humidity) + ",";
jsonData += "\"soil_moisture\":" + String(soilMoisture) + ",";
jsonData += "\"uv_index\":" + String(uvIndex);
jsonData += "}";

// Enviar a la API de Render
http.begin("https://tu-api.onrender.com/predict");
http.addHeader("Content-Type", "application/json");
int httpResponseCode = http.POST(jsonData);
```

### **En el Servidor Principal:**
```python
import requests

def get_irrigation_prediction(sensor_data):
    """Obtener predicciÃ³n del modelo ML en Render"""
    try:
        response = requests.post(
            "https://tu-api.onrender.com/predict",
            json=sensor_data,
            timeout=10
        )
        
        if response.status_code == 200:
            result = response.json()
            return result['prediction']
        else:
            return None
            
    except Exception as e:
        print(f"Error calling ML API: {e}")
        return None
```

## ğŸ“ˆ Monitoreo y Logs

### **Logs en Render:**
- Ve a tu servicio en Render Dashboard
- Click en **Logs** para ver logs en tiempo real
- Monitorea el rendimiento y errores

### **MÃ©tricas:**
- **Uptime:** Tiempo de actividad del servicio
- **Response Time:** Tiempo de respuesta de la API
- **Memory Usage:** Uso de memoria
- **CPU Usage:** Uso de CPU

## ğŸ¯ Beneficios del Despliegue en Render

### **âœ… Ventajas:**
- **Gratis:** Plan gratuito disponible
- **AutomÃ¡tico:** Deploy automÃ¡tico desde GitHub
- **Escalable:** FÃ¡cil escalamiento
- **Monitoreo:** Logs y mÃ©tricas integradas
- **HTTPS:** Certificado SSL automÃ¡tico
- **Global:** CDN global para mejor rendimiento

### **ğŸ”„ Flujo de Trabajo:**
1. **Desarrollo:** Trabaja en local
2. **Commit:** `git commit` y `git push`
3. **Deploy:** Render detecta cambios automÃ¡ticamente
4. **Testing:** Prueba la API desplegada
5. **IntegraciÃ³n:** Conecta con tu sistema IoT

## ğŸš¨ Troubleshooting

### **Problemas Comunes:**

#### **1. Error de Dependencias:**
```
Error: No module named 'pandas'
```
**SoluciÃ³n:** Verifica que `requirements_ml_render.txt` estÃ© correcto

#### **2. Timeout en Build:**
```
Build timeout
```
**SoluciÃ³n:** Reduce las dependencias o usa un plan superior

#### **3. Error de Memoria:**
```
Out of memory
```
**SoluciÃ³n:** Optimiza el modelo o usa un plan superior

#### **4. Modelo no se carga:**
```
Model not loaded
```
**SoluciÃ³n:** Verifica que el entrenamiento se complete correctamente

Â¡Tu modelo ML estarÃ¡ listo para usar en producciÃ³n! ğŸŒ±ğŸ¤–
